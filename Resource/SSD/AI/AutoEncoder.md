컴퓨터 비전에서 생성 모델의 발전 
컴퓨터 비전은 분별 모델을 중심으로 발전해왔으나, 미약하게 GMM이나 HMM, 볼츠만 머신 등의 생성 모델 발전. 하지만 사람 얼굴이나 자연 영상 생성은 넘 볼 수 없는 상황 
2014년 GAN에 의해 획기적 발전. 자연 영상 생성 가능성 제시 
트랜스포머는 또 다른 획기적 진전

## AutoEncoder
지도(레이블 = 클래스정보) 없이도 입력 데이터의 밀집 표현을 학습할 수 있는 신경망 
일반적으로 입력데이터보다 훨씬 낮은 차원을 가지므로 차원 축소 혹은 시각화에 사용됨 

일부 오토인코더는 훈련 데이터와 매우 비슷한 새로운 데이터를 생성할 수 있음 –> 생성모델로 활용 가능

단순한 입력을 출력으로 복사하는 방법을 배움 
네트워크에 제약을 가해, 이 작업을 어렵게 만듬 – 잠재 표현의 크기를 제한하거나, 입력에 잡음을 추가하고 원본 입력을 복원하도 록 네트워크를 훈련 
오토인코더가 데이터 값을 바로 복사하지 못하고, 데이터를 효율적으로 표현하는 방법을 배움 
코딩은 일정 제약 조건하에, 항등 함수를 학습하려는 오토 인코더의 노력 으로 생긴 부산물


오토인코더는 입력을 그대로 출력으로 내놓는 컨볼루션 신경망 
비지도 학습 
특징 추출기 또는 영상 압축기 등으로 활용

입력을 받아 효율적인 내부 표현으로 바꾸고 입력과 가장 가까운 어떤 것 을 출력함 
3가지 구성요소 : 인코더, 디코더, 잠재 공간 (latent vector) 

인코더 : 입력을 내부 표현으로 바꾸는 인코더 네트워크 (인지) § 디코더 : 내부 표현을 출력으로 바꾸는 디코더 네트워크 (생성)

과소 완전 (Undercomplete) 오토인코더 : 내부 표현 (잠재 공간)이 입력 데이터 보다 저차원 (28*28 à 32) 
– 과소 완전 오토인코더는 입력을 코딩으로 간단히 복사할 수 없으며, 입력과 똑 같은 것을 출력하기 위한 방법을 찾아야함

## Denoising Autoencoder (DAE)
입력 데이터에 노이즈를 추가하여 복원을 조금 더 어렵게 만듦 
일반적으로 노이즈는 가우시안 노이즈를 이용 – 바닐라 오토인코더에 비해 유용한 특성을 학습할 수 있도록 함

일반적인 오토인코더와 차이점 
– 입력 데이터에 가우시안 노이즈 추가 
– 입력으로는 노이즈가 추가된 데이터, 레이블로는 원본 데이터 
– 잠재공간에서 좀 더 가치 있는 표현의 추출이 가능함

## Sparse Autoencoder (SAE)
좋은 특성을 추출하도록 ‘희소’라는 제약 기반 오토인코더 – 비용함수에 적절한 항을 추가해 뉴런 수를 감소시키도록 만든다
희소를 구현하는 간단한 방법 
– 잠재 공간을 0~1 사이 값으로 제한하기 위해 시그모이드 활성화 함수 사용
– 잠재 공간 층의 활성화 값에 L1 규제 추가 
– 희소를 강제할 수 있는 로스 함수 추가