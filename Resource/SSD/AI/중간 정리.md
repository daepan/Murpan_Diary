## 1. CNN's
### Convolutional Neural Networks

ML 한계
* MLP의한계
	* 2차원 구조의 영상을 1차원으로 변환하여 입력. 적지 않은 정보 손실로 인한 성능저하
	* 인간은 2차원에서 특징 추출  
	* 수용장(receptive field)이라는 작은 영역에서 특징을 추출

## CNN(Convolutional Neural Networks)
* 컨볼루션 신경망은 인간 시각을 모방
* 딥러닝 중 가장 성공적인 예시
* CNN은 컨볼루션 연산이 핵심
* 일반적인 경우엔 사람이 필터설계 - 가우시안 스무딩, 소벨 에지, 케니 에지
	* 이 필터는 어디서 왔는지?
	* 인식에 최적인가?
	* 데이터셋에 맞는 최적 필터를 사용해야하는지?
* CNN의 핵심 아이디어는 **"최적의 필터를 학습"** 으로 알아냄

### 컨볼루션 층과 풀링 층
* 컨볼루션 층은 표준 컨볼루션에서 몇가지 확장이 필요하다
	* 필터를 여러개 사용해서 다양한 데이터를 추출한다.
	* 하나의 필터는 바이어스 하나를 갖게 된다.
* 컨볼루션 층의 연산
	* 필터 n개 당 출력 특징 맵의 개수가 n개가 나온다.
	![](https://i.imgur.com/OnNbNxA.png)
![](https://i.imgur.com/EX8iiv4.png)

* **가중치 공유weight sharing와 부분 연결성partial connection**
* 입력 특징 맵의 모든 화소가 같은 필터 사용하니 가중치를 공유하는 셈
* 필터는 해당 화소 주위에 국한하여 연산 수행. 가중치 개수가 획기적으로 줄어듦
	* k’개의 h * h * k 필터를 쓰는 경우 가중치는 k’(kh2+1)개

### 컨볼루션층의 연산량
![](https://i.imgur.com/51vnzMp.png)

첫번째층  
– 입력은 256 * 256 * 3 텐서. 0 덧대기하고 보폭 2이고 3 * 3 필터를 64개 사용하므로

출력은 128*  128 * 64 텐서 (필터 모양은 3 * 3 *. 3). – 128 * 128 * 28 * 64번의곱셈수행

두번째층  
– 입력은 128 * 128 *. 64 텐서. 0 덧대기하고. 보폭. 2이고. 5 *. 5 필터를 128개 사용하므

로 출력은 64 * 64 * 128 텐서 (필터 모양은 5 * 5 * 64) – 64 * 64 * 1601 * 128번의곱셈수행

### 풀링층
* 최대 풀링은 필터 안의 화소의 최대값 취함
* 평균 풀링은 필터 안의 화소의 평균을 취함
* 지나친 상세함을 줄이는 효과와 특징 맵의 크기를 줄이는 효과

### 다층 퍼셉트론
* 영상을 입력하기 위해 1차원으로 펼칠때 정보 손실
* FC층의 과다한 매개변수
	* 256 * 256 * 3영상을 입력하려면 196608개의 입력노드 필요

### 인간의 수용장을 모방하는 컨볼루션 신경망 등장
* 1980년 = 네오코그니트론
* 1998년 르쿤의 논문 : LeNet-5를 구현하여 수표 자동 입력 시스템 구현
* 2010년 ImageNet 데이터셋 탄생 ILSVRC 대회 개최 시작
* 2012년 AlexNet이 15.3%오류율로 우승 이후 CNN 관심이 커짐
* 이후 VGG, GoogLeNet, ResNet이 우승
* 물체 검출 분할 추적 자세 추정등의 다양한 모델 등장
* 2014년 생성모델 GAN 등장
* 알고리즘의 발전
	* ReLu 등 활성함수
	* 교차 엔트로피 등 손실 함수
	* 드롭 아웃등 규제 기법
	* Adam 등 옵티마이저 

### 딥러닝의 성공요인
* 인터넷으로 인해 커진 데이터셋
* GPU로 인해 값싸게 병렬처리 가능해짐
* 학습 알고리즘의 발전

### 딥러닝 알고리즘 성능 향상
- 손실함수
- 옵티마이저
- 규제


### 빌딩 블록을 쌓아 만드는 컨볼루션 신경망
* 빌딩 블록 쌓기
	* 보통 컨볼루션층과 풀링층을 번갈아 쌓는다.
	* 풀링층에서는 텐서 깊이가 유지된다.
	* 신경망의 앞부분은 특징 추출, 뒷부분은 분류를 담당한다.
* LeNet 사례
	* C-P-C-P-C-FC-FC
	* 가중치 집합
		* 첫번째 컨볼루션층은 (5 * 5 * 1+1) * 6개의 가중치
		* 두번째 컨볼루션층은 (5 * 5 * 6+1) * 16  
		* 세번째 컨볼루션층은 (5 * 5 * 16+1) * 120 
		* 첫번째 완전연결층은 (120+1) * 84  
		* 두번째 완전연결층은 (84+1) * 10  
		* 총 61,706개의 가중치
* 유연한 구조
	* 문제에 따라 다양한 모양으로 조립 가능
	* 오토 인코더: 입력과 출력이 같은 신경망, 비지도 학습
	* 영상분할을 위한 컨볼루션 신경망

### 컨볼루션 신경망의 학습
* 역전파 학습 알고리즘 사용
	* 컨볼루션층의 커널 화소와 온전연결층의 에지가 가중치에 대당 
	* 풀링층은 가중치 없음
* 특징 학습
	* 학습 알고리즘은 주어진 데이터 셋을 인식하는데 최적인 필터를 알아낸다.
### 텐서 플로 프로그래밍
- 모델을 생성하는 models 모듈
	- Sequential은한갈래텐서가끝까지흐르는경우 
	- Functional API는 텐서가 여러 갈래로 나뉘는 경우
- 층을 쌓는 layers 모듈
	- 완전연결층 Dense, 컨볼루션층 Conv2D, 최대 풀링층 MaxPooling2D, ... 
- 손실함수를 위한 losses 모듈
	- 평균제곱오차 MSE, 교차 엔트로피 categorial_crossentropy, 분할을 위한 focal, ...
- 옵티마지어를 위한 optimizers 모듈 
	- SDG, Adam, AdaGrad. RMSprop 등

### 손실함수
- 교차 엔트로피
	- 주로 분류 문제에서 사용되는 손실 함수로, 모델이 예측한 확률 분포와 실제 정답 분포 사이의 차이를 측정
	- 분류 문제에서 **정확한 클래스 확률 예측**을 유도해 모델이 더욱 확신에 찬 예측을 할 수 있게 합니다.
	- 평균제곱오차와의 차이
		- 평균제곱오차는 예측 값과 실제 값 간의 차이를 제곱하여 평균한 값입니다. 제곱이 적용되므로 큰 오차에 대해 패널티가 더 커지며, 예측 값이 실제 값과 정확히 일치할수록 손실이 낮아집니다.
		- 분류 모델에서의 분류 문제에서 모델의 예측 정확도를 더 높이기 위해서이며, 평균 제곱 오차보다 더 모델이 예측하는 확률분포의 차이를 더 크게 반영하기에 더 많이 사용된다.
- Focal 손실 함수
	- 불균형데이터를 더 효과적으로 학습하기 위한 손실함수
	- 교차 엔트로피 손실 함수에 **가중치를 부여**하여, 모델이 잘 예측하지 못한 **어려운 샘플에 더 높은 손실을 할당**하도록 설계되었으며, 물체 탐색에 주로 이용된다.
- 옵티마이저
	- 기본 옵티마이저에 SGD를 개선하는 전략
	- 모멘텀 적용
		- 이전 운동량이 현재에 영향을 미치는 물리 법칙이며, 가중치 변경 이력이 현재 가중치에 영향을 준다
	- 적응적 학습률 적용
		- 모멘텀의 SGD는 고정된 학습률을 사용하지만, 이는 상황에 따라 학습률을 조절한다.
### 규제
- 다양한 규제 기법
	- 데이터 증강
		- 훈련 집합을 조금씩 변형하여 인위적으로 늘린다.
	- 드랍 아웃
		- 특징 맵을 구성하는 요소 중 일부를 내덤 선택하여 0으로 설정하여 학습에 배제
		- 학습할 떄만 적용하며 예측 과정에서는 적용하지 않는다.
	- 조기 멈춤
		- 성능 향상이 없는 경우 설정한 세대수 이전에 학습을 중지
### 전이 학습
- 어떤 도메인의 데이터로 학습한 모델을 다른 도메인에 적용하여 성능을 향상하는 방법

### 백본 모델
- 유명한 사전 학습 모델
	- VGGNet
		- **깊은 컨볼루션 네트워크**: VGG16은 16개, VGG19는 19개의 레이어로 구성된 깊은 신경망입니다.
		- **단순한 구조**: 모든 레이어가 3x3 컨볼루션 필터와 2x2 맥스 풀링 레이어로 이루어져 있으며, 네트워크 구조가 규칙적입니다.
		- **작은 필터 사용**: 3x3 필터를 여러 개 쌓아 큰 필터를 대체하면서 적은 파라미터로 복잡한 표현 학습이 가능합니다.
		- **계층적 특징 학습**: 깊은 레이어를 통해 더 복잡한 특징을 점진적으로 학습합니다.
	- GoogLeNet
		- **Inception Module**: 1x1, 3x3, 5x5 컨볼루션 필터와 3x3 맥스 풀링을 결합하여 다양한 스케일에서 특징을 추출합니다.
		- **Network-in-Network**: 1x1 컨볼루션으로 차원을 축소하여 계산 비용을 줄이면서 비선형성을 추가해 표현력을 높였습니다.
		- **효율적인 깊은 아키텍처**: 22개 레이어로 구성되어 있으며, 계산 효율성을 유지하도록 설계되었습니다.
		- **보조 분류기 (Auxiliary Classifiers)**: 중간층에 보조 분류기를 추가하여 Gradient Vanishing 문제를 해결하고 학습을 안정화합니다.
	- ResNet
		- **Residual Learning**: Residual Block을 도입하여 Gradient Vanishing 문제를 해결하고, 학습을 용이하게 합니다.
		- **매우 깊은 네트워크**: 50, 101, 152 레이어 등 깊은 네트워크 구조를 통해 복잡한 특징을 학습할 수 있습니다.
		- **Identity Mapping**: Residual Block에 skip connection을 추가하여 신호를 그대로 전달하며, 학습 속도를 높입니다.
		- **복잡성 감소**: Residual Block을 통해 깊은 구조에서도 모델의 복잡성을 줄이고 안정적인 학습을 유지할 수 있습니다.

## 영상 인식
### 인식
- 인식
	- 사람과 달리 컴퓨터 문제는 세부 문제로 구분
	- 별도의 데이터셋과 성능 기준을 가지고 알고리즘을 개발
- 분류
	- 영상에 있는 물체으 부류를 알아내는 부류 확률 벡터를 출력
	- 특정 물체 감지
	- 고양이나 자전거 같은 일반적인 물체를 알아내는 범주
- 검출
	- 영상에서 물체를 찾아 직사각형으로 위치 표현
- 추적
	- 비디오에 나타난 물체의 이동궤적을 표시
- 행동 분류
	- 물체가 수행하는 행동의 종류를 알아내는 문제

### 데이터셋과 방법론의 공진화
- DeepFashion
	- 50부류에 대한 80만장 영상
- Food-101
	- 101부류에 대한 약 10만장 영상
- CheXpert
	- 65240환자의 엑스레이 224315장
- DIV2K  
	- Super-resolution을 위한 고해상도 이미지 (2K 이미지) 1,000장 영상
-  GoPro Dataset  
	- 모션디블러링을위한고속이동촬영동영상
- Flickr2K  
	- Super-resolution을 위한 고해상도 이미지 (2K 이미지) 2,000장 영상

- 합리적이고 공정한 성능 평가 척도가 중요
	- 세부 문제 에 따른 다양한 척도

- 영상 레이블링
	- 많은 노동력이 필요하며 검출 레이블링은 분류 레이블링 보다 어렵고 분할 레이블링은 검출 레이블링보다 어렵다
- 사람과 컴퓨터 비전은 인식하는 방식이 매우 다르다.
	- 사람은 뭐 세밀하고 즉각적이고 추론도 하고 별걸 다한다.
	- 컴퓨터 비전은 세부 문제별로 독립적으로 해결한다. 위에서 말했던 것 처럼 분류
		- 능동적이지 않으며, 사람의 의도를 고안하여 학습하는 것은 먼 미래이다.

### 분류
- 사례 분류
	- 모양과 텍스처가 고정된 특정 물체를 분류
	- 물체를 구성하는 직선과 곡선을 분석하는 기하학적인 방법이 주류
- 범주 분류
	- 코끼리나 자전거 같은 일반 부류의 물체를 분류
	- 부류 내 변화가 아주 심하며, 혼재와 가림을 허용하여 더욱 어려움
	- 고전적으로 부품기반 방법을 사용
- 주로 범주 분류에 대해 많은 연구가 진행되고 있다.
- 미세 분류 문제
	- 부류 내 변화가 크고, 부류간 변화가 적어 아주 어려운 문제
- 설명 가능
	- 인간은 의사결정의 이유를 설명하는 능력이 뛰어나며, 분류 결과에 대한 이유를 설명하지 못하는 치명적 한계가 존재한다.
- 적대적 공격과 방어 전략
	- 딥러닝 모델을 속이려는 시도가 쉽게 통하며, 잡음이 섞이면 타조라고 분류하기도 한다.

### 검출
- 검출 문제
	- 물체의 위치와 함께 부류 정보를 알아내야하므로 분류보다 어렵다
	- 검출 알고리즘은 물체의 위치와 부류 신뢰도를 나타내는 확률벡터를 출력
	- 딥러닝으로 전환하면서 획기적 발전이 이루어짐
	- 성능 척도로는  mAp를 주로 사용한다.
- AP 알고리즘
	- 객체 검출 모델의 성능을 평가하는 방법
	- 주로 객체 검출에서 정밀도(Precision)와 재현율(Recall)을 기준으로 AP 값을 구한다.
	-  **정밀도(Precision)** 가 높을수록: 모델이 예측한 객체 중 실제로 올바르게 탐지된 비율이 높다는 것을 의미합니다. 즉, **잘못된 탐지가 적다는 뜻**으로, 모델이 **오탐(false positive)을 줄이고 정확한 예측을 하고 있다**고 볼 수 있습니다.
	- **재현율(Recall)** 이 높을수록: 실제 객체 중 모델이 탐지한 비율이 높아진다는 의미입니다. 즉, **누락된 탐지가 적다는 뜻**으로, 모델이 **실제 객체를 빠뜨리지 않고 잘 탐지**하고 있음을 나타냅니다.
- 검출 : 고전 방법
	- HOG 특징 추출과정  타일을 생성해서 각 정규화를 통해 확인
	- 후보영역의 사람 여부는 SVM 분류기 사용
	- 후보 영역은 여러 해상도 영상에 슬라이딩 윈도우를 적용하여 생성
	- 이후 DPM 등장으로 물체를 몇개의 부품으로 모델링
- 검출
	- 딥러닝으로 전환되어 RCNN 방법이 되었다.
	- RCNN을 대표하는 두 단계 방법
		- 후보 영역을 생성하고 분류를 통해 물체 여부 판정
		- 영역 제안 단계
			- 물체가 있을 가능성이 높은 영역을 찾는 단계
			- 선택적 알고리즘을 주로 채택
		- 영역 분류 단계
			- 227 * 227로  정규화하여 컨볼루션 신경망을 4096차원 특징 추출
		- 한계
			- 선택적 탐색은 한 장 영상 처리하는데 CPU에서 2초 가량 소요
			- 영역 제안 단계가 병목
	- YOLO가 대표하는 한 단계 방법
		- 위치와 부류 정보를 묶어 참값을 만들고 신경망이 참값을 알아내도록 유도한다.