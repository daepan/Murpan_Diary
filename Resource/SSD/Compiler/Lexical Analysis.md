1. **어휘 분석의 개념**:
    - 어휘 분석은 프로그램의 물리적 설명(텍스트)을 읽어 **토큰**의 시퀀스로 변환하는 과정입니다.
    - 각 토큰은 키워드, 변수 이름 등 논리적으로 의미 있는 소스 코드의 조각을 나타냅니다.
    - 토큰은 **렉심(lexeme)**이라는 실제 텍스트와 관련이 있으며, 이는 토큰을 만든 원본 텍스트 조각을 의미합니다.

2. **정규 표현식과 오토마타**:
    - 정규 표현식(Regular Expressions)은 특정 언어의 문자열을 간결하게 기술하는 방법으로, 다양한 소프트웨어 시스템에서 사용됩니다.
    - 정규 표현식을 **NFA(비결정적 유한 오토마타)**로 변환할 수 있고, 이를 다시 **DFA(결정적 유한 오토마타)**로 변환해 더 효율적으로 매칭을 처리할 수 있습니다.
    - DFA는 주어진 문자열의 길이에 대해 O(m) 시간 내에 처리할 수 있어 NFA보다 빠릅니다.

1. **맥시멀 멘치(Maximal Munch) 규칙**:
    - 어휘 분석 중에는 가능한 한 긴 토큰을 선택하는 **맥시멀 멘치** 규칙을 사용합니다. 이는 입력의 최대 접두사를 매칭하는 방식입니다.
    - 여러 정규 표현식이 동시에 매칭될 경우, 우선순위를 통해 해결하거나, 먼저 정의된 규칙을 선택합니다.

1. **어휘 분석기의 구현**:
    - **자동화된 토큰화**를 위해 NFA와 DFA를 사용해 자동화를 구현할 수 있으며, 이를 통해 입력 문자열을 스캔하고 적절한 토큰을 생성합니다.
    - 스캔 중에 일치하는 정규 표현식이 없으면 오류를 반환하는 **catch-all** 규칙을 추가해 예외 상황을 처리합니다.
2. **어휘 분석의 어려움**:
    
    - FORTRAN, C++ 등 다양한 언어의 문법은 어휘 분석을 복잡하게 만듭니다. 예를 들어, FORTRAN은 공백의 의미가 다를 수 있고, C++은 템플릿 중첩으로 인해 어휘 분석이 복잡해질 수 있습니다.
    - Python은 들여쓰기를 기반으로 블록을 구분하기 때문에, 어휘 분석에서 INDENT와 DEDENT 토큰을 사용해 들여쓰기의 변화를 처리합니다.
6. **어휘 분석의 요약**:
    
    - 어휘 분석은 소스 텍스트를 읽어 토큰으로 나누고, 이 토큰을 구문 분석기에서 프로그램의 구조를 복원하는 데 사용합니다.
    - 정규 표현식과 유한 오토마타를 사용해 이 과정을 최적화하고, 효율적인 스캐닝을 가능하게 합니다.